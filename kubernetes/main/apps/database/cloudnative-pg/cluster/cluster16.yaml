---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/postgresql.cnpg.io/cluster_v1.json
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: postgres16
spec:
  instances: 3
  imageName: ghcr.io/cloudnative-pg/postgresql:16.1-13
  primaryUpdateStrategy: unsupervised
  storage:
    size: 20Gi
    storageClass: local-hostpath
  superuserSecret:
    name: cloudnative-pg-secret
  enableSuperuserAccess: true
  postgresql:
    parameters:
      max_connections: "600"
      max_slot_wal_keep_size: 10GB
      shared_buffers: 512MB
  resources:
    requests:
      cpu: 500m
    limits:
      memory: 4Gi
  monitoring:
    enablePodMonitor: true
    # Ref: https://github.com/cloudnative-pg/cloudnative-pg/issues/2501
    podMonitorMetricRelabelings:
      - { sourceLabels: ["cluster"], targetLabel: cnpg_cluster, action: replace }
      - { regex: cluster, action: labeldrop }
  backup:
    retentionPolicy: 30d
    barmanObjectStore: &barmanObjectStore
      data:
        compression: bzip2
      wal:
        compression: bzip2
        maxParallel: 8
      destinationPath: s3://cloudnative-pg/
      endpointURL: https://s3.turbo.ac
      # Note: serverName version needs to be inclemented
      # when recovering from an existing cnpg cluster
      serverName: &currentCluster postgres16-v2
      s3Credentials:
        accessKeyId:
          name: cloudnative-pg-secret
          key: aws-access-key-id
        secretAccessKey:
          name: cloudnative-pg-secret
          key: aws-secret-access-key
  # # Note: previousCluster needs to be set to the name of the previous
  # # cluster when recovering from an existing cnpg cluster
  # bootstrap:
  #   recovery:
  #     source: &previousCluster postgres16-v1
  # # Note: externalClusters is needed when recovering from an existing cnpg cluster
  # externalClusters:
  #   - name: *previousCluster
  #     barmanObjectStore:
  #       <<: *barmanObjectStore
  #       serverName: *previousCluster
