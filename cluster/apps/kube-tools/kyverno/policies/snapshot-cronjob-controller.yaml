---
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: snapshot-cronjob-controller
  annotations:
    policies.kyverno.io/title: Snapshot CronJob controller
    policies.kyverno.io/subject: PersistentVolumeClaim
    policies.kyverno.io/description: |
      This policy creates a Kopia snapshot CronJob for labeled PersistentVolumeClaims.
      The following label on PVCs are required for this to run:
        - snapshot.home.arpa/enabled
spec:
  generateExistingOnPolicyUpdate: true
  mutateExistingOnPolicyUpdate: true
  rules:
    - name: create-snapshot-cronjob
      match:
        any:
          - resources:
              kinds:
                - PersistentVolumeClaim
              selector:
                matchLabels:
                  app.kubernetes.io/name: "*"
                  app.kubernetes.io/instance: "*"
                  snapshot.home.arpa/enabled: "true"
      context:
        - name: appName
          variable:
            jmesPath: "request.object.metadata.labels.\"app.kubernetes.io/name\""
        - name: claimName
          variable:
            jmesPath: "request.object.metadata.name"
            # TODO(kyverno): https://github.com/kyverno/kyverno/pull/4767
            # jmesPath: "{{ regex_replace_all('^([^-]*)', {{ request.object.metadata.name }}, '${1}') }}" # 'config' instead of 'config-home-assistant-0'
        - name: namespace
          variable:
            jmesPath: "request.object.metadata.namespace"
        - name: nodeAffinity
          variable:
            value:
              labels:
                - key: app.kubernetes.io/name
                  operator: "In"
                  values:
                    - "{{ request.object.metadata.labels.\"app.kubernetes.io/name\" }}"
                - key: app.kubernetes.io/instance
                  operator: "In"
                  values:
                    - "{{ request.object.metadata.labels.\"app.kubernetes.io/instance\" }}"
      generate:
        synchronize: true
        apiVersion: batch/v1
        kind: CronJob
        name: "{{ appName }}-{{ claimName }}-snapshot"
        namespace: "{{ request.object.metadata.namespace }}"
        data:
          metadata:
            labels:
              app.kubernetes.io/name: "{{ request.object.metadata.labels.\"app.kubernetes.io/name\" }}"
              app.kubernetes.io/instance: "{{ request.object.metadata.labels.\"app.kubernetes.io/instance\" }}"
            ownerReferences:
              - apiVersion: "{{ request.object.apiVersion }}"
                kind: "{{ request.object.kind }}"
                name: "{{ request.object.metadata.name }}"
                uid: "{{ request.object.metadata.uid }}"
          spec:
            schedule: "0 3 * * *"
            suspend: false
            concurrencyPolicy: Forbid
            successfulJobsHistoryLimit: 1
            failedJobsHistoryLimit: 2
            jobTemplate:
              spec:
                # Keep at least one job in completed state in accordance to the schedule
                ttlSecondsAfterFinished: 86400
                template:
                  spec:
                    automountServiceAccountToken: false
                    restartPolicy: OnFailure
                    # Stagger jobs to run randomly within X seconds to avoid bringing down all apps at once
                    initContainers:
                      - name: wait
                        image: ghcr.io/onedr0p/kopia:0.12.1@sha256:88106e6bb642ee4cb58b61a335ff55992ee2c03493f1aec804422774cf7cf063
                        command: ["/scripts/sleep.sh"]
                        args: ["1", "1800"]
                    containers:
                      - name: snapshot
                        image: ghcr.io/onedr0p/kopia:0.12.1@sha256:88106e6bb642ee4cb58b61a335ff55992ee2c03493f1aec804422774cf7cf063
                        env:
                          - name: KOPIA_CACHE_DIRECTORY
                            value: /snapshots/{{ namespace }}/{{ appName }}/{{ claimName }}/cache
                          - name: KOPIA_LOG_DIR
                            value: /snapshots/{{ namespace }}/{{ appName }}/{{ claimName }}/logs
                          - name: KOPIA_PASSWORD
                            value: "none"
                        command:
                          - /bin/bash
                          - -c
                          - |-
                            printf "\e[1;32m%-6s\e[m\n" "[01/10] Create repo ..."              && [[ ! -f /snapshots/kopia.repository.f ]] && kopia repository create filesystem --path=/snapshots
                            printf "\e[1;32m%-6s\e[m\n" "[02/10] Connect to repo ..."          && kopia repo connect filesystem --path=/snapshots --override-hostname=cluster --override-username=root
                            printf "\e[1;32m%-6s\e[m\n" "[03/10] Set policies ..."             && kopia policy set /data/{{ namespace }}/{{ appName }}/{{ claimName }} --compression=zstd --keep-latest 14 --keep-hourly 0 --keep-daily 7 --keep-weekly 2 --keep-monthly 0 --keep-annual 0
                            printf "\e[1;32m%-6s\e[m\n" "[04/10] Freeze {{ claimName }} ..."   && fsfreeze -f /data/{{ namespace }}/{{ appName }}/{{ claimName }}
                            printf "\e[1;32m%-6s\e[m\n" "[05/10] Snapshot {{ claimName }} ..." && kopia snap create /data/{{ namespace }}/{{ appName }}/{{ claimName }}
                            printf "\e[1;32m%-6s\e[m\n" "[06/10] Unfreeze {{ claimName }} ..." && fsfreeze -u /data/{{ namespace }}/{{ appName }}/{{ claimName }}
                            printf "\e[1;32m%-6s\e[m\n" "[07/10] List snapshots ..."           && kopia snap list /data/{{ namespace }}/{{ appName }}/{{ claimName }}
                            printf "\e[1;32m%-6s\e[m\n" "[08/10] Show stats ..."               && kopia content stats
                            printf "\e[1;32m%-6s\e[m\n" "[09/10] Show maintenance info ..."    && kopia maintenance info
                            printf "\e[1;32m%-6s\e[m\n" "[10/10] Disconnect from repo ..."     && kopia repo disconnect
                        volumeMounts:
                          - name: data
                            mountPath: "/data/{{ namespace }}/{{ appName }}/{{ claimName }}"
                          - name: snapshots
                            mountPath: /snapshots
                        securityContext:
                          privileged: true
                    volumes:
                      - name: data
                        persistentVolumeClaim:
                          claimName: "{{ claimName }}"
                      - name: snapshots
                        nfs:
                          server: "expanse.${SECRET_PRIVATE_DOMAIN}"
                          path: /eros/Apps/Kopia
                    affinity:
                      podAffinity:
                        requiredDuringSchedulingIgnoredDuringExecution:
                          - topologyKey: kubernetes.io/hostname
                            labelSelector:
                              matchExpressions: "{{ nodeAffinity.labels }}"
