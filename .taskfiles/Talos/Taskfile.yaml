---
# yaml-language-server: $schema=https://taskfile.dev/schema.json
version: "3"

vars:
  # Ref: https://github.com/onedr0p/home-service
  HOME_SERVICE_ADDR: voyager.turbo.ac
  HOME_SERVICE_USER: devin
  HOME_SERVICE_MATCHBOX_DIR: /var/opt/home-service/apps/matchbox/data/config
  # renovate: datasource=docker depName=ghcr.io/siderolabs/installer
  TALOS_VERSION: v1.7.1
  TALOS_SCHEMATIC_ID: d715f723f882b1e1e8063f1b89f237dcc0e3bd000f9f970243af59c8baae0100
  # renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet
  KUBERNETES_VERSION: v1.30.0
  TALOS_SCRIPTS_DIR: "{{.ROOT_DIR}}/.taskfiles/Talos/scripts"

tasks:

  bootstrap:
    desc: Bootstrap Talos
    summary: |
      Args:
        cluster: Cluster to run command against (required)
    prompt: Bootstrap Talos on the '{{.cluster}}' cluster ... continue?
    cmds:
      - task: bootstrap-etcd
        vars: &vars
          cluster: "{{.cluster}}"
      - task: fetch-kubeconfig
        vars: *vars
      - task: bootstrap-apps
        vars: *vars
    requires:
      vars: ["cluster"]

  bootstrap-etcd:
    desc: Bootstrap Etcd
    cmd: until talosctl --context {{.cluster}} --nodes {{.controller}} bootstrap; do sleep 10; done
    vars:
      controller:
        sh: talosctl --context {{.cluster}} config info --output json | jq --raw-output '.endpoints[0]'
    requires:
      vars: ["cluster"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/talosconfig
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1

  bootstrap-apps:
    desc: Bootstrap core apps needed for Talos
    cmds:
      - until kubectl --context {{.cluster}} wait --for=condition=Ready=False nodes --all --timeout=10m; do sleep 10; done
      - helmfile --quiet --kube-context {{.cluster}} --file {{.KUBERNETES_DIR}}/{{.cluster}}/bootstrap/talos/apps/helmfile.yaml apply --skip-diff-on-install --suppress-diff
      - until kubectl --context {{.cluster}} wait --for=condition=Ready nodes --all --timeout=10m; do sleep 10; done
    requires:
      vars: ["cluster"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/talosconfig
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/bootstrap/talos/apps/helmfile.yaml

  fetch-kubeconfig:
    desc: Fetch kubeconfig from Talos controllers
    cmd: |
      talosctl --context {{.cluster}} kubeconfig --nodes {{.controller}} \
          --force --force-context-name {{.cluster}} {{.KUBERNETES_DIR}}/{{.cluster}}
    vars:
      controller:
        sh: talosctl --context {{.cluster}} config info --output json | jq --raw-output '.endpoints[0]'
    requires:
      vars: ["cluster"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/talosconfig
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1

  apply-config:
    desc: Apply Talos configuration to a node
    env:
      TALOS_VERSION: "{{.TALOS_VERSION}}"
      TALOS_SCHEMATIC_ID: "{{.TALOS_SCHEMATIC_ID}}"
      KUBERNETES_VERSION: "{{.KUBERNETES_VERSION}}"
    cmd: |
      sops -d {{.KUBERNETES_DIR}}/{{.cluster}}/bootstrap/talos/matchbox/assets/{{.hostname}}.secret.sops.yaml | \
          envsubst | \
              talosctl --context {{.cluster}} apply-config --mode={{.mode}} --nodes {{.node}} --file /dev/stdin
    vars:
      mode: '{{.mode | default "no-reboot"}}'
      hostname:
        sh: talosctl --context {{.cluster}} --nodes {{.node}} get machineconfig -o jsonpath='{.spec.machine.network.hostname}'
    requires:
      vars: ["cluster", "node"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/talosconfig
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/bootstrap/talos/matchbox/assets/{{.hostname}}.secret.sops.yaml
      - talosctl --context {{.cluster}} --nodes {{.node}} get machineconfig >/dev/null 2>&1

  upgrade:
    desc: Upgrade Talos on a node
    cmd: bash {{.TALOS_SCRIPTS_DIR}}/upgrade.sh "{{.cluster}}" "{{.node}}" "{{.TALOS_SCHEMATIC_ID}}:{{.TALOS_VERSION}}" "{{.rollout}}"
    vars:
      rollout: '{{.rollout | default "false"}}'
    requires:
      vars: ["cluster", "node"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/talosconfig
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.node}} get machineconfig >/dev/null 2>&1

  upgrade-rollout:
    desc: Rollout Talos upgrade on all nodes
    cmds:
      - flux --context {{.cluster}} suspend kustomization --all
      - kubectl cnpg --context {{.cluster}} maintenance set --reusePVC --all-namespaces
      - for: { var: nodes, split: "," }
        task: upgrade
        vars:
          cluster: "{{.cluster}}"
          node: "{{.ITEM}}"
          rollout: "true"
      - kubectl cnpg --context {{.cluster}} maintenance unset --reusePVC --all-namespaces
      - flux --context {{.cluster}} resume kustomization --all
      - task: :kubernetes:delete-failed-pods
        vars:
          cluster: "{{.cluster}}"
    vars:
      nodes:
        sh: talosctl --context {{.cluster}} config info --output json | jq --join-output '[.nodes[]] | join(",")'
    requires:
      vars: ["cluster"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/talosconfig
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.nodes}} get machineconfig >/dev/null 2>&1

  upgrade-k8s:
    desc: Upgrade the clusters k8s version
    cmd: talosctl --context {{.cluster}} --nodes {{.controller}} upgrade-k8s --to {{.KUBERNETES_VERSION}}
    vars:
      controller:
        sh: talosctl --context {{.cluster}} config info --output json | jq --raw-output '.endpoints[0]'
    requires:
      vars: ["cluster"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/talosconfig
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.node}} get machineconfig >/dev/null 2>&1

  reset-node:
    desc: Reset a Talos node and shut it down
    prompt: Reset Talos '{{.node}}' node on the '{{.cluster}}' cluster ... continue?
    cmd: talosctl --context {{.cluster}} reset --nodes {{.node}} --graceful=false
    requires:
      vars: ["cluster", "node"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/talosconfig
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.node}} get machineconfig >/dev/null 2>&1

  reset-cluster:
    desc: Reset all the Talos nodes and shut 'em down
    prompt: Reset Talos on the '{{.cluster}}' cluster ... continue?
    cmd: talosctl --context {{.cluster}} reset --nodes {{.nodes}} --graceful=false
    vars:
      nodes:
        sh: talosctl --context {{.cluster}} config info --output json | jq --join-output '[.nodes[]] | join(",")'
    requires:
      vars: ["cluster"]
    preconditions:
      - test -f {{.KUBERNETES_DIR}}/{{.cluster}}/talosconfig
      - talosctl --context {{.cluster}} config info >/dev/null 2>&1
      - talosctl --context {{.cluster}} --nodes {{.nodes}} get machineconfig >/dev/null 2>&1

  bootstrap-matchbox:
    desc: Bootstrap required Matchbox configuration to Vyos for PXE Boot
    dir: "{{.KUBERNETES_DIR}}/{{.cluster}}/bootstrap/talos/matchbox"
    cmds:
      - for: ["kernel-amd64", "initramfs-amd64.xz"]
        cmd: |
          curl -skL https://factory.talos.dev/image/{{.TALOS_SCHEMATIC_ID}}/{{.TALOS_VERSION}}/{{.ITEM}} | \
              curl -skT - -u "{{.HOME_SERVICE_USER}}:" \
                  sftp://{{.HOME_SERVICE_ADDR}}/{{.HOME_SERVICE_MATCHBOX_DIR}}/assets/{{.ITEM}}
      - find ./assets -type f | xargs -I{} sh -c "sops -d {} | envsubst | curl -skT - -u "{{.HOME_SERVICE_USER}}:" sftp://{{.HOME_SERVICE_ADDR}}/{{.HOME_SERVICE_MATCHBOX_DIR}}/assets/\$(basename {} | sed 's/\.secret\.sops//')"
      - find ./groups -type f | xargs -I{} curl -skT {} -u "{{.HOME_SERVICE_USER}}:" sftp://{{.HOME_SERVICE_ADDR}}/{{.HOME_SERVICE_MATCHBOX_DIR}}/groups/
      - find ./profiles -type f | xargs -I{} curl -skT {} -u "{{.HOME_SERVICE_USER}}:" sftp://{{.HOME_SERVICE_ADDR}}/{{.HOME_SERVICE_MATCHBOX_DIR}}/profiles/
      - ssh -l {{.HOME_SERVICE_USER}} {{.HOME_SERVICE_ADDR}} "cd /var/opt/home-service ; go-task restart-matchbox"
    env:
      TALOS_VERSION: "{{.TALOS_VERSION}}"
      TALOS_SCHEMATIC_ID: "{{.TALOS_SCHEMATIC_ID}}"
      KUBERNETES_VERSION: "{{.KUBERNETES_VERSION}}"
    requires:
      vars: ["cluster"]
